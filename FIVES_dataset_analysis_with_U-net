{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8286652,"sourceType":"datasetVersion","datasetId":4921852}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-24T12:50:38.279126Z","iopub.execute_input":"2025-05-24T12:50:38.279572Z","iopub.status.idle":"2025-05-24T12:50:38.619014Z","shell.execute_reply.started":"2025-05-24T12:50:38.279547Z","shell.execute_reply":"2025-05-24T12:50:38.618228Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.semi_supervised import LabelPropagation\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.metrics import roc_auc_score, f1_score, accuracy_score, jaccard_score, recall_score, confusion_matrix, matthews_corrcoef\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as T\nfrom skimage.morphology import opening, closing, disk\nimport matplotlib.pyplot as plt\n\n# -------- Dataset for FIVES --------\nclass FIVESDataset(Dataset):\n    def __init__(self, img_paths, mask_paths, transform=None):\n        self.img_paths = img_paths\n        self.mask_paths = mask_paths\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.img_paths)\n\n    def __getitem__(self, idx):\n        img = Image.open(self.img_paths[idx]).convert('RGB')\n        mask = Image.open(self.mask_paths[idx]).convert('L')\n        if self.transform:\n            img = self.transform(img)\n            mask = self.transform(mask)\n        mask = (mask > 0).float()\n        return img, mask\n\n# -------- U-Net Model --------\nclass UNet(nn.Module):\n    def __init__(self, in_ch=3, out_ch=1):\n        super().__init__()\n        def CBR(in_channels, out_channels):\n            return nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, 3, padding=1),\n                nn.BatchNorm2d(out_channels),\n                nn.ReLU(inplace=True)\n            )\n        self.enc1 = CBR(in_ch, 64)\n        self.enc2 = CBR(64, 128)\n        self.enc3 = CBR(128, 256)\n        self.pool = nn.MaxPool2d(2)\n        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        self.dec3 = CBR(256+128, 128)\n        self.dec2 = CBR(128+64, 64)\n        self.final = nn.Conv2d(64, out_ch, 1)\n\n    def forward(self, x):\n        e1 = self.enc1(x)\n        e2 = self.enc2(self.pool(e1))\n        e3 = self.enc3(self.pool(e2))\n        d3 = self.up(e3)\n        d3 = self.dec3(torch.cat([d3, e2], dim=1))\n        d2 = self.up(d3)\n        d2 = self.dec2(torch.cat([d2, e1], dim=1))\n        return self.final(d2)\n\n# -------- Training & Inference --------\ndef train_unet(model, loader, epochs=20, lr=1e-3, device='cuda'):\n    model.to(device)\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    loss_fn = nn.BCEWithLogitsLoss()\n    model.train()\n    for ep in range(epochs):\n        epoch_loss = 0.0\n        for imgs, masks in loader:\n            imgs, masks = imgs.to(device), masks.to(device)\n            preds = model(imgs)\n            loss = loss_fn(preds, masks)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n        avg_loss = epoch_loss / len(loader)\n        print(f\"Epoch {ep+1}/{epochs}, Loss: {avg_loss:.4f}\")\n    return model\n\n# -------- Pipeline --------\n# 1. Load FIVES paths\nimg_files = sorted(glob.glob('/kaggle/input/fives-dataset/FIVES A Fundus Image Dataset for AI-based Vessel Segmentation/FIVES A Fundus Image Dataset for AI-based Vessel Segmentation/train/Original/*.png'))\nmask_files = sorted(glob.glob('/kaggle/input/fives-dataset/FIVES A Fundus Image Dataset for AI-based Vessel Segmentation/FIVES A Fundus Image Dataset for AI-based Vessel Segmentation/train/Ground truth/*.png'))\n\n# 2. Train/test split (80/20)\ntrain_imgs, test_imgs, train_masks, test_masks = train_test_split(\n    img_files, mask_files, test_size=0.2, random_state=42\n)\n\n# 3. Dataset & Loader with resizing\ninput_size = (512, 512)\ntfm = T.Compose([\n    T.Resize(input_size),\n    T.ToTensor()\n])\ntrain_ds = FIVESDataset(train_imgs, train_masks, transform=tfm)\ntest_ds = FIVESDataset(test_imgs, test_masks, transform=tfm)\ntrain_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=4)\n\n# 4. Train U-Net\nunet = UNet()\nunet = train_unet(unet, train_loader)\n\n# 5. Test: get probability maps\nunet.eval()\nprobs_list, gts_list, pred_maps_list = [], [], []\nwith torch.no_grad():\n    for img, mask in DataLoader(test_ds, batch_size=1):\n        img = img.to('cuda')\n        logits = unet(img)\n        prob = torch.sigmoid(logits).cpu().numpy().squeeze()\n        gt = mask.numpy().squeeze()\n        probs_list.append(prob)\n        gts_list.append(gt)\n\n# 6. K-NN Graph + Label Propagation refinement\nmetrics = {'AUC':[], 'F1':[], 'Acc':[], 'mIoU':[], 'Sens':[], 'Spec':[], 'MCC':[]}\nfor prob, gt in zip(probs_list, gts_list):\n    # seed selection\n    thresh = 0.3\n    fg_idx = np.where(prob > thresh)\n    bg_idx = np.where(prob < (1 - thresh))\n    pos = np.column_stack([fg_idx[0], fg_idx[1]])\n    neg = np.column_stack([bg_idx[0], bg_idx[1]])\n    neg = neg[np.random.choice(len(neg), size=len(pos), replace=False)]\n    all_coords = np.vstack([pos, neg])\n    labels = np.hstack([np.ones(len(pos)), np.zeros(len(pos))])\n    feats = prob[all_coords[:,0], all_coords[:,1]][:, None]\n    # Label Propagation\n    lp = LabelPropagation(kernel='knn', n_neighbors=12, max_iter=50)\n    lp.fit(feats, labels)\n    preds = lp.predict(feats)\n    # reconstruct map\n    pred_map = np.zeros_like(prob, dtype=int)\n    for (y,x), p in zip(all_coords, preds):\n        pred_map[y, x] = p\n    # morphology cleanup\n    se = disk(1)\n    pred_map = closing(opening(pred_map, se), se)\n    pred_maps_list.append(pred_map)\n    # metrics\n    flat_gt = gt.flatten()\n    flat_pred = pred_map.flatten()\n    metrics['AUC'].append(roc_auc_score(flat_gt, prob.flatten()))\n    metrics['F1'].append(f1_score(flat_gt, flat_pred))\n    metrics['Acc'].append(accuracy_score(flat_gt, flat_pred))\n    metrics['mIoU'].append(jaccard_score(flat_gt, flat_pred))\n    metrics['Sens'].append(recall_score(flat_gt, flat_pred))\n    tn, fp, fn, tp = confusion_matrix(flat_gt, flat_pred).ravel()\n    metrics['Spec'].append(tn / (tn + fp))\n    metrics['MCC'].append(matthews_corrcoef(flat_gt, flat_pred))\n\n# 7. Report results\nfor k, v in metrics.items():\n    print(f\"{k}: {np.mean(v):.4f} Â± {np.std(v):.4f}\")\n\n# 8. Visualize some test samples\nnum_samples = min(3, len(probs_list))\nfor i in range(num_samples):\n    img_tensor, mask_tensor = test_ds[i]\n    orig = img_tensor.permute(1,2,0).numpy()\n    gt = gts_list[i]\n    pred = pred_maps_list[i]\n    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n    axes[0].imshow(orig)\n    axes[0].set_title('Original')\n    axes[1].imshow(gt, cmap='gray')\n    axes[1].set_title('Ground Truth')\n    axes[2].imshow(pred, cmap='gray')\n    axes[2].set_title('Prediction')\n    for ax in axes:\n        ax.axis('off')\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}